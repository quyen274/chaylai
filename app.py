import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import requests
from bs4 import BeautifulSoup
from streamlit_option_menu import option_menu

# C·∫•u h√¨nh Streamlit
st.set_page_config(page_title="Ph√¢n T√≠ch Xu H∆∞·ªõng S·∫£n Ph·∫©m", layout="wide")

# Thanh ƒëi·ªÅu h∆∞·ªõng
with st.sidebar:
    selected = option_menu(
        "Menu",
        ["Crawl D·ªØ Li·ªáu", "Ph√¢n T√≠ch D·ªØ Li·ªáu"],
        icons=["cloud-download", "bar-chart"],
        menu_icon="cast",
        default_index=0,
    )

# H√†m crawl d·ªØ li·ªáu t·ª´ Shopee
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
import pandas as pd
import time

def crawl_shopee(keyword="labubu", max_pages=1):
    options = Options()
    options.add_argument("--headless")  # Ch·∫°y kh√¥ng giao di·ªán
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-gpu")
    options.add_argument("window-size=1920,1080")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    # ƒê∆∞·ªùng d·∫´n ƒë·∫øn chromedriver
    service = Service("path_to_chromedriver")  # Thay path_to_chromedriver b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø

    driver = webdriver.Chrome(service=service, options=options)
    product_data = []

    try:
        for page in range(max_pages):
            url = f"https://shopee.vn/search?keyword={keyword}&page={page}"
            driver.get(url)
            time.sleep(5)  # Ch·ªù trang load xong

            # L·∫•y danh s√°ch s·∫£n ph·∫©m
            items = driver.find_elements(By.CLASS_NAME, "shopee-search-item-result__item")
            for item in items:
                try:
                    title = item.find_element(By.CLASS_NAME, "ie3A+n").text
                    price = item.find_element(By.CLASS_NAME, "ZEgDH9").text
                    product_data.append({"Product": title, "Price": price})
                except Exception:
                    continue

        driver.quit()
        return pd.DataFrame(product_data)

    except Exception as e:
        driver.quit()
        print(f"L·ªói: {e}")
        return pd.DataFrame()

# H√†m gi·∫£ l·∫≠p crawl d·ªØ li·ªáu t·ª´ Facebook
def crawl_facebook(keyword="labubu", max_posts=50):
    # ƒê√¢y l√† h√†m gi·∫£ l·∫≠p. ƒê·ªÉ crawl th·ª±c t·∫ø, b·∫°n c·∫ßn s·ª≠ d·ª•ng Facebook Graph API ho·∫∑c c√°c c√¥ng c·ª• ph√π h·ª£p kh√°c.
    return pd.DataFrame({
        "Post": [f"{keyword} is amazing!", f"Best gift for {keyword} lovers!", f"Limited {keyword} stocks!"],
        "Likes": [150, 230, 300],
        "Comments": [20, 35, 50]
    })

# Trang Crawl D·ªØ Li·ªáu
if selected == "Crawl D·ªØ Li·ªáu":
    st.title("üõí Crawl D·ªØ Li·ªáu T·ª´ Shopee & Facebook")

    # Crawl t·ª´ Shopee
    st.subheader("üîó Crawl t·ª´ Shopee")
    keyword = st.text_input("Nh·∫≠p t·ª´ kh√≥a t√¨m ki·∫øm (v√≠ d·ª•: labubu):", value="labubu")
    max_pages = st.slider("S·ªë trang c·∫ßn crawl:", 1, 5, 1)

    if st.button("Crawl Shopee"):
        shopee_data = crawl_shopee(keyword, max_pages)
        if not shopee_data.empty:
            st.write(f"K·∫øt qu·∫£ crawl t·ª´ Shopee ({len(shopee_data)} s·∫£n ph·∫©m):")
            st.dataframe(shopee_data)
        else:
            st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu t·ª´ Shopee.")

    # Crawl t·ª´ Facebook
    st.subheader("üí¨ Crawl t·ª´ Facebook")
    if st.button("Crawl Facebook"):
        facebook_data = crawl_facebook(keyword=keyword, max_posts=50)
        if not facebook_data.empty:
            st.write(f"K·∫øt qu·∫£ crawl t·ª´ Facebook ({len(facebook_data)} b√†i ƒëƒÉng):")
            st.dataframe(facebook_data)
        else:
            st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu t·ª´ Facebook.")

# Trang Ph√¢n T√≠ch D·ªØ Li·ªáu
if selected == "Ph√¢n T√≠ch D·ªØ Li·ªáu":
    st.title("üìà Ph√¢n T√≠ch D·ªØ Li·ªáu S·∫£n Ph·∫©m")

    # Ki·ªÉm tra d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c crawl
    if 'shopee_data' in locals() and not shopee_data.empty:
        st.subheader("üìä D·ªØ Li·ªáu T·ª´ Shopee")
        st.dataframe(shopee_data)

        # Chuy·ªÉn ƒë·ªïi c·ªôt Sales th√†nh s·ªë nguy√™n
        shopee_data['Sales'] = shopee_data['Sales'].str.extract('(\d+)').astype(int)

        # Hi·ªÉn th·ªã t·ªïng s·ªë s·∫£n ph·∫©m v√† t·ªïng l∆∞·ª£t b√°n
        st.write(f"T·ªïng s·ªë s·∫£n ph·∫©m: {len(shopee_data)}")
        st.write(f"T·ªïng l∆∞·ª£t b√°n: {shopee_data['Sales'].sum()}")

        # Bi·ªÉu ƒë·ªì s·∫£n ph·∫©m b√°n ch·∫°y nh·∫•t
        st.subheader("üî• Top 10 S·∫£n Ph·∫©m B√°n Ch·∫°y Nh·∫•t")
        top_products = shopee_data.sort_values(by='Sales', ascending=False).head(10)
        fig, ax = plt.subplots()
        ax.barh(top_products['Product'], top_products['Sales'], color='skyblue')
        ax.set_xlabel('S·ªë L∆∞·ª£ng B√°n')
        ax.set_title('Top 10 S·∫£n Ph·∫©m B√°n Ch·∫°y Nh·∫•t tr√™n Shopee')
        st.pyplot(fig)
    else:
        st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu t·ª´ Shopee. Vui l√≤ng crawl d·ªØ li·ªáu tr∆∞·ªõc.")

    # Ki·ªÉm tra d·ªØ li·ªáu t·ª´ Facebook
    if 'facebook_data' in locals() and not facebook_data.empty:
        st.subheader("üí¨ D·ªØ Li·ªáu T·ª´ Facebook")
        st.dataframe(facebook_data)

        # Bi·ªÉu ƒë·ªì t∆∞∆°ng t√°c tr√™n Facebook
        st.subheader("üëç T∆∞∆°ng T√°c Tr√™n Facebook")
        fig, ax = plt.subplots()
        ax.bar(facebook_data['Post'], facebook_data['Likes'], label='Likes', color='blue')

